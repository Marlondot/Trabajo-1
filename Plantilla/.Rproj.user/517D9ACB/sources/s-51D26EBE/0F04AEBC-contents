---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
output:
  pdf_document:
    number_sections: true
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.pos = "H", fig.align = "center")
library(tidyverse)
library(knitr)
library(kableExtra)
library(leaps)
source("funciones.R")
```

\input{titlepage}
\thispagestyle{empty}
\tableofcontents
\listoffigures
\listoftables

\newpage

\pagestyle{myheadings}
\setcounter{page}{3}

\section{Ejercicio 1}

\subsection{Análisis de las variables}

\noindent
Es de nuestro interés ajustar un modelo de regresión lineal múltiple acorde a las 72 observaciones de la base de datos, cuyas filas están compuestas por las variables: $y$: Riesgo de infección, $x_1$: Duración de la estadía, $x_2$: Rutina de cultivos, $x_3$: Número de camas, $x_4$: Censo promedio diario y $x_5$: Número de enfermeras.
Para ello comenzaremos con un análisis a la matriz de correlaciones entre ellas: 


```{r,fig.cap="Matriz de correlaciones"}
base <- read.table("Equipo34.txt", header = T)
pairs(base, lower.panel = myPanel.cor, upper.panel = panel.smooth, diag.panel = myPanel.box, labels = names(base))
```
\noindent
Se puede notar una alta dependencia lineal entre $X_3$ y $X_4$, $X_3$ y $X_5$, y, $X_4$ y $X_5$. Además, notar que las correlaciones entre la variable respuesta $Y$ y las variables $X_1$ $X_2$ son las más altas en relación a la primera, con respectivos valores de $0.55$ y $0.49$, suponiendo una relación lineal débil entre las dos variables en los dos casos.

\subsection{Ajuste del modelo}
\noindent
Ahora, con las observaciones de la base de datos, procederemos a hacer el ajuste del siguiente modelo de regresión lineal múltiple:

$$ y_i = \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} +  \beta_3x_{3i} + \beta_4x_{4i} + \beta_5x_{5i} + \varepsilon_i, \ \varepsilon_i \stackrel{iid}{\sim} N(0, \sigma^2);  \ 1 \leq i \leq 72$$


```{r,include=FALSE}
modelo <- lm(Y ~ ., base)
modelo$coefficients
```
\noindent
Así, el ajuste, redondeando los coeficientes a cuatro cifras decimales, nos resultará en la ecuación:

$$ \hat{y}_i = 0.9586 + 0.2682x_{1i} + 0.0409x_{2i} +  -0.0007x_{3i} + 0.0009x_{4i} + 0.001x_{5i} ;  \ 1 \leq i \leq 72$$

\subsection{Análisis de varianza}
\noindent
Se desea verificar la significancia de la regresión usando la tabla ANOVA, mediante la cual compararemos el siguiente juego de hipotesis:

$$
\begin{cases}
\begin{aligned}
H_0&: \beta_1  = \cdots = \beta_5 = 0 \\
H_1&: \text{Al menos un } \beta_j \neq 0
\end{aligned}
\end{cases}
$$
\noindent
Para la cual obtendremos lo siguiente:

```{r,fig.cap="Tabla ANOVA del modelo"}
tabla.anova <- myAnova(modelo)
row.names(tabla.anova) <- c("Regresión", "Error")
tabla.anova %>%
  kable(row.names = T, escape = F,
        col.names = c("Suma de cuadrados", "gl", "Cuadrado Medio", "$F_0$" ,"Valor P"),
        align = "c", caption = "Tabla ANOVA para el modelo", booktab = T, digits = 4) %>%
  kable_styling(latex_options = "HOLD_position")
```
\noindent
Donde $F_0 = \frac{MSR}{MSE} \sim F_{5,66} \text{ bajo } H_0$
\noindent
Podemos concluir así que con un nivel de significancia del 5% al menos uno de los coeficientes es significativo, esto del rechazo de $H_0$ por el Valor P.

\subsection{Análisis de varianza}
\noindent
Ahora procederemos hacer un análisis marginal de cada uno de los coeficientes usando la siguiente prueba para $j = 1, \cdots, 5$: 

$$
\begin{cases}
\begin{aligned}
H_0&: \beta_j = 0 \\
H_1&: \beta_j \neq 0
\end{aligned}
\end{cases}
$$
\noindent
con $T_0 = \frac{\hat{\beta}_j}{se(\hat{\beta}_j)} \sim t_{66} \text{ bajo } H_0$
\noindent
Para lo que usaremos la siguiente tabla:

```{r}
tabla.coef <- summary(modelo)$coefficients 
row.names(tabla.coef) <- c("$\\beta_0$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$", "$\\beta_4$","$\\beta_5$")
tabla.coef %>%
  kable(row.names = T, escape = F,
        col.names = c("Estimación", "Error estándar", "$T_0$", "Valor P"),
        align = "c", caption = "Resumen de los coeficientes", booktab = T, digits = 4) %>%
  kable_styling(latex_options = "HOLD_position")
```

\noindent
Se puede observar que con un nivel de significancia de $\alpha=0.05$, a nivel marginal las únicas variables que tienen un efecto significativo en la respuesta son $x_1$ y $x_2$ que representan la duración de la estadía y la rutina de cultivos respectivamente.

\noindent
Notar que: $\hat{\beta}_1=0.2682$ indica que por un aumento unitario en la duración de la estadía $x_1$, la media de la variable respuesta aumentará en $0.2682$ unidades; de la misma manera, $\hat{\beta}_2=0.0409$ indica que por cada aumento en una unidad en la rutina de cultivos, la media de la variable respuesta aumentará en $0.0409$ unidades; estos dos casos siempre y cuando las otras variables se mantengan constantes.

\subsection{Cálculo y análisis del coeficiente de determinación múltiple}
\noindent
Tenemos que el coeficiente de determinación multiple, denotado por $R^2$ se define como:

$$
R^2=\frac{SSR}{SST}=1-\frac{SSE}{SST}
$$
\noindent
con $SSR$: Suma de cuadrados de la regresión , $SSE$: Suma de cuadrados de los residuales, y $SST=SSR+SSE$. Así tenemos, con los datos calculados anterioremente en la tabla ANOVA, que:

$$R^2=\frac{52.3209}{52.3209+64.1423}=0.4492483$$
\noindent
Tal $R^2$ nos dice que un $44.92\%$ de la variabilidad total en el Riesgo de infección (Variable respuesta) es explicado por el modelo RLM propuesto.

\section{Ejercicio 2}
\noindent
De la tabla resumen de coeficientes que se mostró anteriormente, obtenemos que las 3 variables con el mayor valor p (y mayor a 0.05) son $\beta_3,\beta_4$ y $\beta_5$, que equivalen a el número de camas, censo promedio diario y número de enfermeras respectivamente.

\noindent
Para probar la significancia simultánea de las anteriores variables se usará el siguiente juego de hipotesis:

$$
\begin{cases}
\begin{aligned}
H_0 &:  \beta_3 = \beta_4 =\beta_5 = 0 \\
H_1 &: Algún\ \beta_j \not = 0, \ j = 3,4,5,  
\end{aligned}
\end{cases}
$$
\noindent
De la tabla de todas las regresiones posibles se extraen los siguientes modelos de interés:


```{r echo=FALSE}
posibles_regresiones = myAllRegTable(modelo)
tabla_anova = myAnova(modelo)
tabla.coef <- myAnova(modelo)
# SSredu =  67.452
# SSFull =  64.142
# r = 3
# n = 72
# p = 6
# MSH = (SSredu - SSFull)/r
# MSE = SSFull/(n-p)
# (F0 = MSH/MSE)
interes <- posibles_regresiones[c(6,31),]
row.names(interes) = c("Reducido","Completo")
x = c("Numero de variables", "$R^2$", "$R^2$ ajustado","SSE", "CP", "Variables del modelo")
interes %>%
   kable( row.names = T,escape = F,
          col.names = x, booktab = T) %>%
   kable_styling(latex_options = "HOLD_position")
  
```
\noindent
Para medir la importancia de $\beta_3,\beta_4$ y $\beta_5$, se usará la suma de cuadrados extra, de la anterior tabla, con el fin de obtener el siguiente estadístico de prueba para la prueba de hipótesis:

$$F_{0} = \frac{MSextra}{MSE(\beta_0 , \beta_1 ,\beta_2,\beta_3 , \beta_4 ,\beta_5)} = \frac{MSR(\beta_3 , \beta_4 ,\beta_5|\beta_0 , \beta_1 ,\beta_2 )}{MSE(\beta_0 , \beta_1 ,\beta_2,\beta_3 , \beta_4 ,\beta_5)} = \frac{SSR(\beta_3 , \beta_4 ,\beta_5|\beta_0 , \beta_1 ,\beta_2)/ 3 }{MSE(\beta_0 , \beta_1 ,\beta_2,\beta_3 , \beta_4 ,\beta_5)}$$
$$ = \frac{[SSE(\beta_0 , \beta_1 ,\beta_2) - SSE(\beta_0 , \beta_1 ,\beta_2,\beta_3 , \beta_4 ,\beta_5)]/3}{MSE(\beta_0 , \beta_1 ,\beta_2,\beta_3 , \beta_4 ,\beta_5)}= \frac{[SSE(Reducido) - SSE(Completo)]/3}{MSE(Completo)}$$

$$= \frac{[67.452 - 64.142]/3}{0.971853}= 1.1353 $$
\noindent 
El criterio de rechazo de la hipótesis nula es $F_{0} >f_{0.05,3,66}$. Como $F_{0} = 1.1353$ y $f_{0.05,3,66} = 2.7437$ luego $F_{0} \ngtr f_{0.05,3,66}$. Esto quiere decir que no se puede rechazar la hipótesis nula, es decir, la prueba concluye que es posible descartar el número de camas, el censo promedio diario y el número de enfermeras.
 

\section{Ejercicio 3}

\noindent
Ahora, nos interesa realizar una prueba lineal generalizada, con el fin de concluir si dos de los parámetros que no son significativos de manera marginal ($\beta_3$ y $\beta_4$) siguen sin serlo de manera conjunta, además de concluir si el efecto de la duración de la estadía es 6 veces el efecto de rutina de cultivo. Se desea contrastar así las siguientes hipótesis:


$$
\begin{cases}
\begin{aligned}
H_0&: \beta_3 = \beta_4=0;\beta_1 = 6\beta_2  \\
H_1&: \beta_3 \neq 0 \ ;\ \beta_4\neq 0 \ ;\ \beta_1 = 6\beta_2
\end{aligned}
\end{cases}
$$

\noindent
Podemos reescribir la prueba de la siguiente manera:

$$
\begin{cases}
\begin{aligned}
H_0&: \mathbf{L} \beta = 0 \\
H_1&: \mathbf{L} \beta  \neq 0
\end{aligned}
\end{cases}
$$
\noindent
Donde:


 $$L = \begin{bmatrix} 0 & 1 & -6 & 0 & 0 & 0\\
                       0 & 0 & 0 & 1 & 1 & 1\\
                      \end{bmatrix}$$

\noindent
Se define el modelo reducido como sigue

$$ y_i =\beta_0+6\beta_2x_{1i} + \beta_2x_{2i} + \varepsilon_i, \ \varepsilon_i \stackrel{iid}{\sim} N(0, \sigma^2);  \ 1 \leq i \leq 72$$
\noindent
y se toma al modelo completo como el que se definió anteriormente.

```{r,include=FALSE}
COPY<-data.frame(base)
COPY <- COPY %>%
  mutate(X3 = 6*X1 + X2)
modred <- lm(Y ~ X3, data = COPY)
```


\noindent
Se calculó el estadístico $F_0 = \frac{MSH}{MSE} \sim F_{2,66} \text{ bajo } H_0$ como se muestra a continuación
$$F_0 = \frac{\frac{SSE(RM) - SSE(FM)}{\text{g.l}_{SSE(RM)} - \text{g.l}_{SSE(FM)}}}{MSE} = \frac{\frac{104.082 - 64.142}{ 70 - 66}}{1.4869}=6.715314 $$
Así, $P(F_{2, 66} >F_{0obs})$ = `r round(pf(6.715314, 2, 66, lower.tail = F),4)` que con un nivel de significancia del 0.05 nos permite rechazar la hipotesis nula, por ende, hay evidencia estadística para concluir que las covariables Número de camas y Censo promedio diario, conjuntamente, no ayudan a explicar el riesgo de infección, además de que cuando se aumenta en una unidad la duración de la estadía la media de la variable respuesta no aumentará 6 veces el aumento dado por incrementar una unidad en la rutina de cultivos, es decir $\beta_1 \neq 6\beta_2$.


\section{Ejercicio 4}

\subsection{Validación de los supuestos}

```{r}
# gráfica y prueba de normalidad de Shapiro-Wilk
myQQnorm(modelo)
```
\noindent
Como podemos ver, el gráfico de normalidad se comporta de una buena manera ya que los puntos están bastante cercanos a la recta de normalidad. Además si nos fijamos en la prueba de hipótesis que sería:

$$H_0: r \sim  N(\mu,\sigma^2)$$ 
$$ H_1:r \neq  N(\mu,\sigma^2)$$
\noindent
Podemos notar que el p-value es 0.8976 por lo cual si tomamos un $\alpha=0.05$ es claro que  $0.8976>\alpha$ por lo cual no negamos la hipótesis nula y concluimos que los residuales se distribuyen de manera normal.

\subsection{Gráfico de los residuales estudentizados vs valores ajustados}

```{r}
# CÃ¡lculo de residuales estudentizados y valores ajustados
res.stud <- round(rstandard(modelo), 4)
yhat <- round(modelo$fitted.values, 4)
# GrÃ¡fica de Residuales estudentizados vs. Valores ajustados
plot(yhat, res.stud, xlab = "Valores Ajustados", 
     ylab = "Residuales Estudentizados")
abline(h = 0, lty = 2, lwd = 2, col = 2)
abline(h = -3, lty = 2, lwd = 2, col = 2)
abline(h = 3, lty = 2, lwd = 2, col = 2)
```
\noindent
Podemos ver que la varianza de los errores se ve constante dado que no se ve ninguna forma en particular, además se ve que ningún punto sobre pasa el límite $|r_i|>3$ por lo cual no hay datos atípicos.

\subsection{Puntos de balanceo}
\noindent
Para hallar los puntos de balanceo realizamos el cálculo:
$$h_{ii}>\frac{2*p}{n}=\frac{2*6}{72}=\frac{1}{6}$$
\noindent
Ahora lo comparamos con los hat values y los siguientes son los puntos mayores al hii:
```{r,include=FALSE}
# CÃ¡lculo de errores estÃ¡ndar de los valores ajustados
se.yhat <- round(predict(modelo, se.fit = T)$se.fit, 4)
# Residuales crudos del modelo
residuals <- round(modelo$residuals, 4)
# Distancias de Cook
Cooks.D <- round(cooks.distance(modelo), 4)
# Valores de la diagonal de la matriz H
hii.value <- round(hatvalues(modelo), 4)
# Dffits
Dffits <- round(dffits(modelo), 4)
# Tabla de diagnÃ³sticos
data.frame(base, yhat, se.yhat, residuals, res.stud, Cooks.D, hii.value, Dffits)
```

```{r,echo=FALSE}
c(head(hii.value),tail(hii.value))%>% 
kable(booktabs = TRUE,format = "latex", caption="\\label{box-cox}Primeros y ultimos valores hat values",format.args = list( decimal.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "condensed","HOLD_position"),
  position = "center", font_size=10,full_width = FALSE)
```
\noindent
Este sería un resumen de la tabla completa la cual reducimos para no ver una tabla tan enorme y solo sacamos los valores que nos interesan:


```{r,echo=FALSE}
Puntos_Balanceo=(hii.value[c(3,13,28,31,34,41,46,49,53,63,70)])
Puntos_Balanceo%>% 
kable(booktabs = TRUE,format = "latex", caption="\\label{box-cox}Hat-values > 0.166",format.args = list( decimal.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "condensed","HOLD_position"),
  position = "center", font_size=10,full_width = FALSE)
  
```
\noindent
Como podemos ver tenemos 11 datos de balanceo los cuales son los datos: 3,13,28,31,34,41,46,49,53,63,70 los cuales son mayores a $\frac{1}{6}$

\subsection{Puntos influenciales}
\noindent
Para los puntos influenciables nos ayudaremos del diagnóstico DFFITS el cual nos dice que una observación será influenciable si $|DFFITS_i|>2*\sqrt{\frac{p}{n}}$ con el cual si reemplazamos $|DFFITS_i|>2*\sqrt{\frac{6}{72}}=0.577$.
\noindent
Nuestra tabla de DFFITS es algo como:

```{r,echo=FALSE}
c(head(Dffits),tail(Dffits))%>% 
kable(booktabs = TRUE,format = "latex", caption="\\label{box-cox}Primeros y ultimos valores DFFITS",format.args = list( decimal.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "condensed","HOLD_position"),
  position = "center", font_size=10,full_width = FALSE)
```
\noindent
De la tabla completa sacamos los valores los cuales nos cumplan la condición que estamos buscando con la cual nos queda la siguiente tabla:


```{r,echo=FALSE}
Puntos_Influenciales=(Dffits[c(28,46,53,63)])
Puntos_Influenciales%>% 
kable(booktabs = TRUE,format = "latex", caption="\\label{box-cox}|DFFITS| > 0.577",format.args = list( decimal.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "condensed","HOLD_position"),
  position = "center", font_size=10,full_width = FALSE)
```
\noindent
Como podemos ver solo tenemos 4 datos influenciales, los cuales son el 28,46,53,63.

\subsection{Conclusión}
\noindent
Como conclusión podemos decir que el modelo no es del todo acertado dado que los datos 28,46,53,63 son datos influenciales y a la vez son datos de balanceo. Lo cual hace que esos datos halen el modelo en esta dirección y son observaciones que tienen valores inusuales por lo cual se recomendaría quitar dichas observaciones.