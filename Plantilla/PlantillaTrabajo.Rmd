---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
output:
  pdf_document:
    number_sections: true
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: "es"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.pos = "H", fig.align = "center")
library(tidyverse)
library(knitr)
library(kableExtra)
library(leaps)
source("funciones.R")
```

\input{titlepage}
\thispagestyle{empty}
\tableofcontents
\listoffigures
\listoftables

\newpage

\pagestyle{myheadings}
\setcounter{page}{3}

\section{Ejercicio 1}

\subsection{Análisis de las variables}

Es de nuestro interés ajustar un modelo de regresión lineal múltiple acorde a las 72 observaciones de la base de datos, cuyas filas están compuestas por las variables: $y$: Riesgo de infección, $x_1$: Duración de la estadía, $x_2$: Rutina de cultivos, $x_3$: Número de camas, $x_4$: Censo promedio diario y $x_5$: Número de enfermeras.
Para ello comenzaremos con un análisis a la matriz de correlaciones entre ellas: 


```{r,fig.cap="Matriz de correlaciones"}
base <- read.table("Equipo34.txt", header = T)
pairs(base, lower.panel = myPanel.cor, upper.panel = panel.smooth, diag.panel = myPanel.box, labels = names(base))
```

Se puede notar una alta dependencia lineal entre $X_3$ y $X_4$, $X_3$ y $X_5$, y, $X_4$ y $X_5$. Además, notar que las correlaciones entre la variable respuesta $Y$ y las variables $X_1$ $X_2$ son las más altas en relación a la primera, con respectivos valores de $0.55$ y $0.49$, suponiendo una relación lineal débil entre las dos variables en los dos casos.

\subsection{Ajuste del modelo}

Ahora, con las observaciones de la base de datos, procederemos a hacer el ajuste del siguiente modelo de regresión lineal múltiple:

$$ y_i = \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} +  \beta_3x_{3i} + \beta_4x_{4i} + \beta_5x_{5i} + \varepsilon_i, \ \varepsilon_i \stackrel{iid}{\sim} N(0, \sigma^2);  \ 1 \leq i \leq 72$$


```{r,include=FALSE}
modelo <- lm(Y ~ ., base)
modelo$coefficients
```
Así, el ajuste, redondeando los coeficientes a cuatro cifras decimales, nos resultará en la ecuación:

$$ \hat{y}_i = 0.9586 + 0.2682x_{1i} + 0.0409x_{2i} +  -0.0007x_{3i} + 0.0009x_{4i} + 0.001x_{5i} ;  \ 1 \leq i \leq 72$$

\subsection{Análisis de varianza}

Se desea verificar la significancia de la regresión usando la tabla ANOVA, mediante la cual compararemos el siguiente juego de hipotesis:

$$
\begin{cases}
\begin{aligned}
H_0&: \beta_1  = \cdots = \beta_5 = 0 \\
H_1&: \text{Al menos un } \beta_j \neq 0
\end{aligned}
\end{cases}
$$
Para la cual obtendremos lo siguiente:

```{r,fig.cap="Tabla ANOVA del modelo"}
tabla.anova <- myAnova(modelo)
row.names(tabla.anova) <- c("Regresión", "Error")
tabla.anova %>%
  kable(row.names = T, escape = F,
        col.names = c("Suma de cuadrados", "gl", "Cuadrado Medio", "$F_0$" ,"Valor P"),
        align = "c", caption = "Tabla ANOVA para el modelo", booktab = T, digits = 4) %>%
  kable_styling(latex_options = "HOLD_position")
```

Donde $F_0 = \frac{MSR}{MSE} \sim F_{5,66} \text{ bajo } H_0$

Podemos concluir así que con un nivel de significancia del 5% al menos uno de los coeficientes es significativo, esto del rechazo de $H_0$ por el Valor P.

\subsection{Análisis de varianza}

Ahora procederemos hacer un análisis marginal de cada uno de los coeficientes usando la siguiente prueba para $j = 1, \cdots, 5$: 

$$
\begin{cases}
\begin{aligned}
H_0&: \beta_j = 0 \\
H_1&: \beta_j \neq 0
\end{aligned}
\end{cases}
$$
con $T_0 = \frac{\hat{\beta}_j}{se(\hat{\beta}_j)} \sim t_{66} \text{ bajo } H_0$

Para lo que usaremos la siguiente tabla:

```{r}
tabla.coef <- summary(modelo)$coefficients 
row.names(tabla.coef) <- c("$\\beta_0$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$", "$\\beta_4$","$\\beta_5$")
tabla.coef %>%
  kable(row.names = T, escape = F,
        col.names = c("Estimación", "Error estándar", "$T_0$", "Valor P"),
        align = "c", caption = "Resumen de los coeficientes", booktab = T, digits = 4) %>%
  kable_styling(latex_options = "HOLD_position")
```

Se puede observar que con un nivel de significancia de $\alpha=0.05$, a nivel marginal las únicas variables que tienen un efecto significativo en la respuesta son $x_1$ y $x_2$ que representan la duración de la estadía y la rutina de cultivos respectivamente.

Notar que: $\hat{\beta}_1=0.2682$ indica que por un aumento unitario en la duración de la estadía $x_1$, la media de la variable respuesta aumentará en $0.2682$ unidades; de la misma manera, $\hat{\beta}_2=0.0409$ indica que por cada aumento en una unidad en la rutina de cultivos, la media de la variable respuesta aumentará en $0.0409$ unidades; estos dos casos siempre y cuando las otras variables se mantengan constantes.

\subsection{Cálculo y análisis del coeficiente de determinación múltiple}

Tenemos que el coeficiente de determinación multiple, denotado por $R^2$ se define como:

$$
R^2=\frac{SSR}{SST}=1-\frac{SSE}{SST}
$$
con $SSR$: Suma de cuadrados de la regresión , $SSE$: Suma de cuadrados de los residuales, y $SST=SSR+SSE$. Así tenemos, con los datos calculados anterioremente en la tabla ANOVA, que:

$$R^2=\frac{52.3209}{52.3209+64.1423}=0.4492483$$
Tal $R^2$ nos dice que un $44.92\%$ de la variabilidad total en el Riesgo de infección (Variable respuesta) es explicado por el modelo RLM propuesto.

\section{Ejercicio 2}

De la tabla resumen de coeficientes que se mostró anteriormente, obtenemos que las 3 variables con el mayor valor p (y mayor a 0.05) son $\beta_3,\beta_4$ y $\beta_5$, que equivalen a el número de camas, censo promedio diario y número de enfermeras respectivamente.


Para probar la significancia simultánea de las anteriores variables se usará el siguiente juego de hipotesis:

$$
\begin{cases}
\begin{aligned}
H_0 &:  \beta_3 = \beta_4 =\beta_5 = 0 \\
H_1 &: Algún\ \beta_j \not = 0, \ j = 3,4,5,  
\end{aligned}
\end{cases}
$$

De la tabla de todas las regresiones posibles se extraen los siguientes modelos de interés:


```{r echo=FALSE}
posibles_regresiones = myAllRegTable(modelo)

tabla_anova = myAnova(modelo)
tabla.coef <- myAnova(modelo)

# SSredu =  67.452
# SSFull =  64.142
# r = 3
# n = 72
# p = 6
# MSH = (SSredu - SSFull)/r
# MSE = SSFull/(n-p)
# (F0 = MSH/MSE)

interes <- posibles_regresiones[c(6,31),]
row.names(interes) = c("Reducido","Completo")
x = c("Numero de variables", "$R^2$", "$R^2$ ajustado","SSE", "CP", "Variables del modelo")
interes %>%
   kable( row.names = T,escape = F,
          col.names = x, booktab = T) %>%
   kable_styling(latex_options = "HOLD_position")

  
```
Para medir la importancia de $\beta_3,\beta_4$ y $\beta_5$, se usará la suma de cuadrados extra, de la anterior tabla, con el fin de obtener el siguiente estadístico de prueba para la prueba de hipótesis:

$$F_{0} = \frac{MSextra}{MSE(\beta_0 , \beta_1 ,\beta_2,\beta_3 , \beta_4 ,\beta_5)} = \frac{MSR(\beta_3 , \beta_4 ,\beta_5|\beta_0 , \beta_1 ,\beta_2 )}{MSE(\beta_0 , \beta_1 ,\beta_2,\beta_3 , \beta_4 ,\beta_5)} = \frac{SSR(\beta_3 , \beta_4 ,\beta_5|\beta_0 , \beta_1 ,\beta_2)/ 3 }{MSE(\beta_0 , \beta_1 ,\beta_2,\beta_3 , \beta_4 ,\beta_5)}$$
$$ = \frac{[SSE(\beta_0 , \beta_1 ,\beta_2) - SSE(\beta_0 , \beta_1 ,\beta_2,\beta_3 , \beta_4 ,\beta_5)]/3}{MSE(\beta_0 , \beta_1 ,\beta_2,\beta_3 , \beta_4 ,\beta_5)}= \frac{[SSE(Reducido) - SSE(Completo)]/3}{MSE(Completo)}$$

$$= \frac{[67.452 - 64.142]/3}{0.971853}= 1.1353 $$
 
El criterio de rechazo de la hipótesis nula es $F_{0} >f_{0.05,3,66}$. Como $F_{0} = 1.1353$ y $f_{0.05,3,66} = 2.7437$ luego $F_{0} \ngtr f_{0.05,3,66}$. Esto quiere decir que no se puede rechazar la hipótesis nula, es decir, la prueba concluye que es posible descartar el número de camas, el censo promedio diario y el número de enfermeras.
 

\section{Ejercicio 3}

\section{Ejercicio 4}

\subsection{Validación de los supuestos}

```{r}
# gráfica y prueba de normalidad de Shapiro-Wilk
myQQnorm(modelo)
```

Como podemos ver, el gráfico de normalidad se comporta de una buena manera ya que los puntos están bastante cercanos a la recta de normalidad. Además si nos fijamos en la prueba de hipótesis que sería:

$$H_0: r \sim  N(\mu,\sigma^2)$$ 
$$ H_1:r \neq  N(\mu,\sigma^2)$$

Podemos notar que el p-value es 0.8976 por lo cual si tomamos un $\alpha=0.05$ es claro que  $0.8976>\alpha$ por lo cual no negamos la hipótesis nula y concluimos que los residuales se distribuyen de manera normal.

\subsection{Gráfico de los residuales estudentizados vs valores ajustados}

```{r}
# CÃ¡lculo de residuales estudentizados y valores ajustados
res.stud <- round(rstandard(modelo), 4)
yhat <- round(modelo$fitted.values, 4)

# GrÃ¡fica de Residuales estudentizados vs. Valores ajustados
plot(yhat, res.stud, xlab = "Valores Ajustados", 
     ylab = "Residuales Estudentizados")
abline(h = 0, lty = 2, lwd = 2, col = 2)
abline(h = -3, lty = 2, lwd = 2, col = 2)
abline(h = 3, lty = 2, lwd = 2, col = 2)
```

Podemos ver que la varianza de los errores se ve constante dado que no se ve ninguna forma en particular, además se ve que ningún punto sobre pasa el límite $|r_i|>3$ por lo cual no hay datos atípicos.

\subsection{Puntos de balanceo}

Para hallar los puntos de balanceo realizamos el cálculo:
$$h_{ii}>\frac{2*p}{n}=\frac{2*6}{72}=\frac{1}{6}$$

Ahora lo comparamos con los hat values y los siguientes son los puntos mayores al hii:
```{r,include=FALSE}

# CÃ¡lculo de errores estÃ¡ndar de los valores ajustados
se.yhat <- round(predict(modelo, se.fit = T)$se.fit, 4)
# Residuales crudos del modelo
residuals <- round(modelo$residuals, 4)
# Distancias de Cook
Cooks.D <- round(cooks.distance(modelo), 4)
# Valores de la diagonal de la matriz H
hii.value <- round(hatvalues(modelo), 4)
# Dffits
Dffits <- round(dffits(modelo), 4)
# Tabla de diagnÃ³sticos
data.frame(base, yhat, se.yhat, residuals, res.stud, Cooks.D, hii.value, Dffits)
```

```{r,echo=FALSE}
c(head(hii.value),tail(hii.value))%>% 
kable(booktabs = TRUE,format = "latex", caption="\\label{box-cox}Primeros y ultimos valores hat values",format.args = list( decimal.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "condensed","HOLD_position"),
  position = "center", font_size=10,full_width = FALSE)
```

Este sería un resumen de la tabla completa la cual reducimos para no ver una tabla tan enorme y solo sacamos los valores que nos interesan:


```{r,echo=FALSE}



Puntos_Balanceo=(hii.value[c(3,13,28,31,34,41,46,49,53,63,70)])

Puntos_Balanceo%>% 
kable(booktabs = TRUE,format = "latex", caption="\\label{box-cox}Hat-values > 0.166",format.args = list( decimal.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "condensed","HOLD_position"),
  position = "center", font_size=10,full_width = FALSE)
  
```

Como podemos ver tenemos 11 datos de balanceo los cuales son los datos: 3,13,28,31,34,41,46,49,53,63,70 los cuales son mayores a $\frac{1}{6}$

\subsection{Puntos influenciales}

Para los puntos influenciables nos ayudaremos del diagnóstico DFFITS el cual nos dice que una observación será influenciable si $|DFFITS_i|>2*\sqrt{\frac{p}{n}}$ con el cual si reemplazamos $|DFFITS_i|>2*\sqrt{\frac{6}{72}}=0.577$.

Nuestra tabla de DFFITS es algo como:

```{r,echo=FALSE}
c(head(Dffits),tail(Dffits))%>% 
kable(booktabs = TRUE,format = "latex", caption="\\label{box-cox}Primeros y ultimos valores DFFITS",format.args = list( decimal.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "condensed","HOLD_position"),
  position = "center", font_size=10,full_width = FALSE)
```

De la tabla completa sacamos los valores los cuales nos cumplan la condición que estamos buscando con la cual nos queda la siguiente tabla:


```{r,echo=FALSE}
Puntos_Influenciales=(Dffits[c(28,46,53,63)])

Puntos_Influenciales%>% 
kable(booktabs = TRUE,format = "latex", caption="\\label{box-cox}|DFFITS| > 0.577",format.args = list( decimal.mark = ".")) %>%
  kable_styling(latex_options = c("striped", "condensed","HOLD_position"),
  position = "center", font_size=10,full_width = FALSE)

```

Como podemos ver solo tenemos 4 datos influenciales, los cuales son el 28,46,53,63.

\subsection{Conclusión}

Como conclusión podemos decir que el modelo no es del todo acertado dado que los datos 28,46,53,63 son datos influenciales y a la vez son datos de balanceo. Lo cual hace que esos datos halen el modelo en esta dirección y son observaciones que tienen valores inusuales por lo cual se recomendaría quitar dichas observaciones.